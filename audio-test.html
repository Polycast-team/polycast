<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Transcription Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
        }
        .controls {
            text-align: center;
            margin: 30px 0;
        }
        button {
            font-size: 18px;
            padding: 15px 30px;
            margin: 10px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .record-btn {
            background-color: #4CAF50;
            color: white;
        }
        .record-btn:hover {
            background-color: #45a049;
        }
        .record-btn:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        .recording {
            background-color: #f44336 !important;
        }
        .status {
            text-align: center;
            margin: 20px 0;
            font-weight: bold;
            font-size: 16px;
        }
        .log {
            background-color: #f8f8f8;
            border: 1px solid #ddd;
            padding: 15px;
            border-radius: 5px;
            max-height: 400px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
            margin-top: 20px;
        }
        .transcript {
            background-color: #e8f5e8;
            border: 2px solid #4CAF50;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
            min-height: 50px;
        }
        .error {
            background-color: #ffe8e8;
            border: 2px solid #f44336;
            color: #d32f2f;
        }
        .success {
            color: #2e7d32;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ OpenAI Audio Transcription Test</h1>
        
        <div class="controls">
            <button id="recordBtn" class="record-btn">üé§ Hold to Record</button>
            <button id="clearBtn">üóëÔ∏è Clear Log</button>
        </div>
        
        <div id="status" class="status">Ready to record</div>
        
        <div class="transcript" id="transcript">
            <strong>Transcript will appear here...</strong>
        </div>
        
        <div class="log" id="log"></div>
    </div>

    <script>
        class SimpleAudioTest {
            constructor() {
                this.ws = null;
                this.audioContext = null;
                this.mediaStream = null;
                this.audioProcessor = null;
                this.isRecording = false;
                this.audioBuffer = [];
                this.isConnected = false;
                
                this.recordBtn = document.getElementById('recordBtn');
                this.clearBtn = document.getElementById('clearBtn');
                this.status = document.getElementById('status');
                this.transcript = document.getElementById('transcript');
                this.log = document.getElementById('log');
                
                this.setupEventListeners();
                this.connect();
            }
            
            log(message, type = 'info') {
                const timestamp = new Date().toLocaleTimeString();
                const color = type === 'error' ? '#d32f2f' : type === 'success' ? '#2e7d32' : '#333';
                this.log.innerHTML += `<div style="color: ${color};">[${timestamp}] ${message}</div>`;
                this.log.scrollTop = this.log.scrollHeight;
                console.log(message);
            }
            
            updateStatus(message, type = 'info') {
                this.status.textContent = message;
                this.status.className = `status ${type}`;
            }
            
            setupEventListeners() {
                this.recordBtn.addEventListener('mousedown', () => this.startRecording());
                this.recordBtn.addEventListener('mouseup', () => this.stopRecording());
                this.recordBtn.addEventListener('mouseleave', () => this.stopRecording());
                
                // Also support spacebar
                document.addEventListener('keydown', (e) => {
                    if (e.code === 'Space' && !this.isRecording) {
                        e.preventDefault();
                        this.startRecording();
                    }
                });
                
                document.addEventListener('keyup', (e) => {
                    if (e.code === 'Space') {
                        e.preventDefault();
                        this.stopRecording();
                    }
                });
                
                this.clearBtn.addEventListener('click', () => {
                    this.log.innerHTML = '';
                    this.transcript.innerHTML = '<strong>Transcript will appear here...</strong>';
                });
            }
            
            async connect() {
                try {
                    this.updateStatus('Connecting to OpenAI...', 'info');
                    this.log('üîå Connecting to OpenAI Realtime API...');
                    
                    // Connect to backend proxy (adjust URL for your deployment)
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    const backendHost = window.location.hostname === 'localhost' ? 'localhost:3001' : 'polycast-server.onrender.com';
                    const url = `${protocol}//${backendHost}/openai-proxy`;
                    
                    this.ws = new WebSocket(url);
                    
                    this.ws.onopen = () => {
                        this.log('‚úÖ Connected to OpenAI proxy', 'success');
                        this.isConnected = true;
                        this.updateStatus('Connected - ready to test audio', 'success');
                    };
                    
                    this.ws.onmessage = (event) => {
                        try {
                            const message = JSON.parse(event.data);
                            this.handleMessage(message);
                        } catch (error) {
                            this.log('‚ùå Error parsing message: ' + error.message, 'error');
                        }
                    };
                    
                    this.ws.onclose = () => {
                        this.log('üîå Connection closed', 'error');
                        this.isConnected = false;
                        this.updateStatus('Disconnected', 'error');
                    };
                    
                    this.ws.onerror = (error) => {
                        this.log('‚ùå WebSocket error: ' + error, 'error');
                        this.updateStatus('Connection error', 'error');
                    };
                    
                } catch (error) {
                    this.log('‚ùå Failed to connect: ' + error.message, 'error');
                    this.updateStatus('Connection failed', 'error');
                }
            }
            
            handleMessage(message) {
                const eventType = message.type;
                
                switch (eventType) {
                    case 'session.created':
                        this.log('‚úÖ Session created, configuring...', 'success');
                        this.sendConfiguration();
                        break;
                        
                    case 'session.updated':
                        this.log('‚úÖ Session configured successfully', 'success');
                        this.initializeAudio();
                        break;
                        
                    case 'input_audio_buffer.cleared':
                        this.log('üóëÔ∏è Audio buffer cleared');
                        break;
                        
                    case 'input_audio_buffer.committed':
                        this.log('‚úÖ Audio buffer committed', 'success');
                        break;
                        
                    case 'conversation.item.created':
                        this.log('üìù Conversation item created');
                        break;
                        
                    case 'conversation.item.input_audio_transcription.completed':
                        this.log('‚úÖ Transcription completed!', 'success');
                        this.transcript.innerHTML = `<strong>‚úÖ SUCCESS:</strong> "${message.transcript}"`;
                        this.transcript.className = 'transcript success';
                        this.updateStatus('Transcription successful!', 'success');
                        break;
                        
                    case 'conversation.item.input_audio_transcription.failed':
                        this.log('‚ùå Transcription failed: ' + JSON.stringify(message.error), 'error');
                        this.transcript.innerHTML = `<strong>‚ùå FAILED:</strong> ${JSON.stringify(message.error)}`;
                        this.transcript.className = 'transcript error';
                        this.updateStatus('Transcription failed', 'error');
                        break;
                        
                    default:
                        if (!eventType.includes('delta') && !eventType.includes('transcript')) {
                            this.log('üì® Received: ' + eventType);
                        }
                        break;
                }
            }
            
            sendConfiguration() {
                const config = {
                    type: 'session.update',
                    session: {
                        modalities: ['audio', 'text'],
                        instructions: 'You are a helpful assistant. Just acknowledge what the user says.',
                        voice: 'alloy',
                        input_audio_format: 'pcm16',
                        output_audio_format: 'pcm16',
                        turn_detection: null,
                        input_audio_transcription: {
                            model: 'whisper-1'
                        }
                    }
                };
                
                this.log('üì§ Sending session configuration...');
                this.ws.send(JSON.stringify(config));
            }
            
            async initializeAudio() {
                try {
                    this.log('üé§ Initializing audio...');
                    
                    // First get media stream to detect sample rate
                    const tempConstraints = {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: false,
                        autoGainControl: false
                    };
                    
                    const tempStream = await navigator.mediaDevices.getUserMedia({ audio: tempConstraints });
                    const audioTrack = tempStream.getAudioTracks()[0];
                    const settings = audioTrack.getSettings();
                    const actualSampleRate = settings.sampleRate || 24000;
                    
                    this.log(`üîß MediaStream: ${settings.sampleRate}Hz, ${settings.channelCount}ch`);
                    tempStream.getTracks().forEach(track => track.stop());
                    
                    // Create AudioContext with matching sample rate
                    this.audioContext = new AudioContext({ sampleRate: actualSampleRate });
                    
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                    }
                    
                    this.log(`üîß AudioContext: ${this.audioContext.sampleRate}Hz, state: ${this.audioContext.state}`);
                    
                    // Get final media stream
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { ...tempConstraints, sampleRate: actualSampleRate }
                    });
                    
                    const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                    
                    // Set up audio processor
                    const bufferSize = 4096;
                    this.audioProcessor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);
                    
                    this.audioProcessor.onaudioprocess = (event) => {
                        if (this.isRecording) {
                            const inputData = event.inputBuffer.getChannelData(0);
                            
                            // Check for audio content
                            let hasAudio = false;
                            for (let i = 0; i < inputData.length; i++) {
                                if (Math.abs(inputData[i]) > 0.005) {
                                    hasAudio = true;
                                    break;
                                }
                            }
                            
                            if (hasAudio) {
                                // Resample to 24kHz if needed
                                const targetSampleRate = 24000;
                                const currentSampleRate = this.audioContext.sampleRate;
                                
                                let processedData = inputData;
                                if (currentSampleRate !== targetSampleRate) {
                                    processedData = this.resampleAudio(inputData, currentSampleRate, targetSampleRate);
                                }
                                
                                const pcm16 = this.float32ToPCM16(processedData);
                                this.audioBuffer.push(pcm16);
                                
                                if (this.audioBuffer.length === 1) {
                                    this.log(`üé§ Recording... (${currentSampleRate}Hz ‚Üí ${targetSampleRate}Hz)`);
                                }
                            }
                        }
                    };
                    
                    source.connect(this.audioProcessor);
                    this.audioProcessor.connect(this.audioContext.destination);
                    
                    this.log('‚úÖ Audio initialized successfully', 'success');
                    this.updateStatus('Ready to record - click and hold button or hold spacebar', 'success');
                    
                } catch (error) {
                    this.log('‚ùå Audio initialization failed: ' + error.message, 'error');
                    this.updateStatus('Audio setup failed', 'error');
                }
            }
            
            startRecording() {
                if (!this.isConnected || this.isRecording) return;
                
                this.log('üé§ Starting recording...');
                this.updateStatus('üé§ Recording... (release to send)', 'info');
                this.recordBtn.textContent = 'üî¥ Recording...';
                this.recordBtn.classList.add('recording');
                
                // Clear audio buffer
                this.ws.send(JSON.stringify({ type: 'input_audio_buffer.clear' }));
                this.audioBuffer = [];
                this.isRecording = true;
            }
            
            stopRecording() {
                if (!this.isRecording) return;
                
                this.log('üé§ Stopping recording...');
                this.updateStatus('Processing audio...', 'info');
                this.recordBtn.textContent = 'üé§ Hold to Record';
                this.recordBtn.classList.remove('recording');
                this.isRecording = false;
                
                if (this.audioBuffer.length > 0) {
                    this.log(`üì§ Sending ${this.audioBuffer.length} audio chunks...`);
                    
                    // Calculate duration
                    let totalBytes = 0;
                    this.audioBuffer.forEach(chunk => totalBytes += chunk.byteLength);
                    const durationMs = (totalBytes / 2 / 24000 * 1000).toFixed(2);
                    this.log(`üîß Audio: ${totalBytes} bytes, ${durationMs}ms duration`);
                    
                    // Send audio chunks
                    this.audioBuffer.forEach(chunk => {
                        const base64Audio = this.arrayBufferToBase64(chunk);
                        this.ws.send(JSON.stringify({
                            type: 'input_audio_buffer.append',
                            audio: base64Audio
                        }));
                    });
                    
                    // Commit and create response
                    this.ws.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
                    this.ws.send(JSON.stringify({ type: 'response.create' }));
                    
                } else {
                    this.log('‚ö†Ô∏è No audio captured', 'error');
                    this.updateStatus('No audio detected', 'error');
                }
            }
            
            resampleAudio(inputBuffer, inputSampleRate, outputSampleRate) {
                if (inputSampleRate === outputSampleRate) {
                    return inputBuffer;
                }
                
                const ratio = inputSampleRate / outputSampleRate;
                const outputLength = Math.round(inputBuffer.length / ratio);
                const output = new Float32Array(outputLength);
                
                for (let i = 0; i < outputLength; i++) {
                    const sourceIndex = i * ratio;
                    const index = Math.floor(sourceIndex);
                    const fraction = sourceIndex - index;
                    
                    if (index + 1 < inputBuffer.length) {
                        output[i] = inputBuffer[index] * (1 - fraction) + inputBuffer[index + 1] * fraction;
                    } else {
                        output[i] = inputBuffer[inputBuffer.length - 1];
                    }
                }
                
                return output;
            }
            
            float32ToPCM16(float32Array) {
                const pcm16 = new ArrayBuffer(float32Array.length * 2);
                const view = new DataView(pcm16);
                
                for (let i = 0; i < float32Array.length; i++) {
                    const sample = Math.max(-1, Math.min(1, float32Array[i]));
                    const int16Value = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    view.setInt16(i * 2, Math.round(int16Value), true);
                }
                
                return pcm16;
            }
            
            arrayBufferToBase64(buffer) {
                const bytes = new Uint8Array(buffer);
                let binary = '';
                for (let i = 0; i < bytes.byteLength; i++) {
                    binary += String.fromCharCode(bytes[i]);
                }
                return btoa(binary);
            }
        }
        
        // Start the test when page loads
        window.addEventListener('load', () => {
            new SimpleAudioTest();
        });
    </script>
</body>
</html>