const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai');
const config = require('../config/config');

let genAI;
let model;

/**
 * Initializes the Google Generative AI client and model.
 * @throws {Error} If Google API key is missing.
 */
function initializeLLM() {
    if (!config.googleApiKey) {
        throw new Error('Google API Key (GOOGLE_API_KEY) is not configured in .env');
    }
    if (!genAI) {
        console.log('[LLM Service] Initializing Google Generative AI...');
        genAI = new GoogleGenerativeAI(config.googleApiKey);
        model = genAI.getGenerativeModel({
            model: 'models/gemini-2.0-flash',
            // Safety settings can be adjusted if needed
            // safetySettings: [
            //     { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
            //     { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
            // ],
        });
        console.log('[LLM Service] Google Generative AI initialized.');
    }
}

/**
 * Translates the given text to the target language using the configured LLM.
 * @param {string} text The text to translate.
 * @param {string} targetLanguage The target language (e.g., 'Spanish').
 * @returns {Promise<string>} The translated text.
 * @throws {Error} If initialization fails or translation API call fails.
 */
async function translateText(text, targetLanguage) {
    initializeLLM(); // Ensure LLM is initialized

    if (!text || text.trim().length === 0) {
        console.log('[LLM Service] Skipping translation for empty text.');
        return '';
    }

    // Refined prompt acknowledging input source and handling inaccuracies
    const prompt = `You are acting as a real-time translator. The following input is a live English transcription generated by Azure Speech-to-Text, which may contain inaccuracies or misheard words.

Your task is to translate this transcription into ${targetLanguage}. Prioritize translating the *intended meaning* based on the context. If parts of the transcription seem nonsensical due to likely transcription errors, use your best judgment to infer the speaker's intent while remaining as faithful as possible to the original meaning. However, if the transcription appears reasonably coherent, translate it directly.

Output *only* the final ${targetLanguage} translation, without any explanations, commentary, or introductory phrases like "Here is the translation:".

Input Transcription:
"${text}"

${targetLanguage} Translation:`; // Added label for clarity but LLM should ignore based on instructions

    // For demonstration purposes, print the exact prompt that will be sent:
    console.log("--- LLM Prompt ---");
    console.log(prompt);
    console.log("--- End LLM Prompt ---");

    try {
        console.log(`[LLM Service] Sending text to Gemini for translation to ${targetLanguage}...`);
        const result = await model.generateContent(prompt);
        const response = result.response;
        const translatedText = response.text().trim();
        console.log(`[LLM Service] Received translation: "${translatedText}"`);
        return translatedText;
    } catch (error) {
        console.error('[LLM Service] Error during translation API call:', error);
        // Check for specific safety/block reasons
        if (error.response && error.response.promptFeedback && error.response.promptFeedback.blockReason) {
             throw new Error(`Translation blocked due to safety settings: ${error.response.promptFeedback.blockReason}`);
        } else if (error instanceof Error) {
             throw new Error(`LLM API Error: ${error.message}`);
        } else {
            throw new Error('Unknown error during LLM translation');
        }
    }
}

/**
 * Batch translates the given text into multiple target languages using a single LLM call.
 * @param {string} text The text to translate.
 * @param {string[]} targetLanguages The target languages (e.g., ['Spanish', 'Portuguese', ...]).
 * @returns {Promise<Object>} An object mapping each language to its translation.
 */
async function translateTextBatch(text, targetLanguages) {
    initializeLLM();
    if (!text || text.trim().length === 0) {
        console.log('[LLM Service] Skipping translation for empty text batch.');
        return Object.fromEntries(targetLanguages.map(lang => [lang, '']));
    }
    const langsList = targetLanguages.join(', ');
    const prompt = `You are acting as a real-time interpreter. The following input is a live English transcription generated by a voice-to-text model, which may contain inaccuracies or misheard words. Your task is to translate this transcription into the following languages in order: ${langsList}. Output the translations in that order, separated by double slashes (//), with no extra text. If the transcription does not make sense, use your best judgment to infer the speaker's intent and act as an interpreter, but if it does, be as faithful as possible to the meaning.\n\nInput: "${text}"\n\nTranslations:`;
    console.log("--- LLM Batch Prompt ---");
    console.log(prompt);
    console.log("--- End LLM Batch Prompt ---");
    try {
        console.log(`[LLM Service] Sending text to Gemini for batch translation to: ${langsList}`);
        const result = await model.generateContent(prompt);
        const response = result.response;
        const translationsRaw = response.text().trim();
        console.log(`[LLM Service] Received batch translation: "${translationsRaw}"`);
        // Split by // and map to languages
        const translationArr = translationsRaw.split(/\s*\/\/\s*/);
        const translations = {};
        for (let i = 0; i < targetLanguages.length; ++i) {
            translations[targetLanguages[i]] = translationArr[i] ? translationArr[i].trim() : '';
        }
        return translations;
    } catch (error) {
        console.error('[LLM Service] Error during batch translation API call:', error);
        if (error.response && error.response.promptFeedback && error.response.promptFeedback.blockReason) {
             throw new Error(`Batch translation blocked due to safety settings: ${error.response.promptFeedback.blockReason}`);
        } else if (error instanceof Error) {
             throw new Error(`LLM API Error: ${error.message}`);
        } else {
            throw new Error('Unknown error during LLM batch translation');
        }
    }
}

/**
 * Gets a Spanish dictionary-style definition for the given English word.
 * @param {string} word The English word to define.
 * @param {string} [context] Optional context sentence to help identify the correct meaning.
 * @returns {Promise<Object>} The definition object with Spanish definition and example.
 * @throws {Error} If initialization fails or API call fails.
 */
/**
 * This function has been removed as part of the transition to a new dictionary workflow.
 * 
 * The old implementation used to generate dictionary entries directly from Gemini.
 * The new approach will use the disambiguate-word endpoint with a new prompt format
 * that returns word//definition//translation format.
 */
async function getWordDefinition(word, context = '') {
    console.log('[LLM Service] getWordDefinition function is deprecated and has been removed.');
    // Return a minimal object to prevent errors in case any code still calls this function
    return {
        translation: '',
        partOfSpeech: '',
        wordFrequency: 3,
        definitions: [
            {
                text: 'Definition unavailable. Using new workflow.',
                example: '',
                usageFrequency: 3
            }
        ]
    };
}

// Helper to extract JSON from LLM response text
function extractJsonFromText(text) {
    try {
        // Find JSON in the response (it might be wrapped in code blocks or not)
        let jsonMatch = text.match(/```(?:json)?([^`]*?)```/s);
        let jsonStr = jsonMatch ? jsonMatch[1].trim() : text;
        
        // If still not JSON object, try to find anything that looks like JSON
        if (!jsonStr.startsWith('{') && !jsonStr.startsWith('[')) {
            jsonMatch = text.match(/(\{.*\})/s);
            jsonStr = jsonMatch ? jsonMatch[0] : text;
        }
        
        // Try to parse the JSON
        return JSON.parse(jsonStr);
    } catch (e) {
        console.error('[LLM Service] Failed to parse JSON:', e);
        
        // Last resort - try to extract just the JSON object
        const lastMatch = text.match(/\{[^]*\}/);
        if (lastMatch) {
            try {
                return JSON.parse(lastMatch[0]);
            } catch (e2) {
                console.error('[LLM Service] Failed final JSON parse attempt:', e2);
                throw e2;
            }
        } else {
            throw e;
        }
    }
}

// Helper to normalize the definition format for backward compatibility
function normalizeDefinitionFormat(response) {
    try {
        // If we have the new format with definitions array
        if (response.definitions && Array.isArray(response.definitions) && response.definitions.length > 0) {
            // Copy the first definition to the root level for backward compatibility
            if (!response.definition && response.definitions[0].text) {
                response.definition = response.definitions[0].text;
            }
            if (!response.example && response.definitions[0].example) {
                response.example = response.definitions[0].example;
            }
        } 
        // If we have the old format without definitions array, create one
        else if (response.definition && !response.definitions) {
            response.definitions = [{
                text: response.definition,
                example: response.example || ''
            }];
        }
        
        return response;
    } catch (e) {
        console.error('[LLM Service] Error normalizing definition format:', e);
        // Return whatever we had before the normalization attempt
        return response;
    }
}

module.exports = {
    translateText,
    translateTextBatch,
    getWordDefinition
};